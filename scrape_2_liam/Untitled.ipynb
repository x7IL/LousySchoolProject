{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Challenge 5 ou mini-projet de Sécurité"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Boisel Jules\n",
    "Xu William\n",
    "Savadoux Baptiste"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "import feedparser\n",
    "import dateparser\n",
    "import deepl\n",
    "translator = deepl.Translator(\n",
    "    \"nop\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "def enlever(text):\n",
    "    return text.replace(\"\\n\", \"\").replace(\"\\t\", \"\").replace(\"\\b\", \"\").replace(\"\\r\", \"\").replace(\"\\a\", \"\").replace(\"\\v\", \"\").replace(\"  \",\"\").replace(\" \",\"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "def New_CSV_site(emplacement , list_site):  # ecrit dans un csv (c'est juste plus simple)\n",
    "    with open(emplacement, \"w\", newline='', encoding='utf-8') as f:\n",
    "        for i in list_site:\n",
    "            f.write(i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "liste_site_bon_atombon_rss = [] # définition d'une variable global pour pouvoir ajouter les sites dans les 2 fonctions\n",
    "liste_site_bon_atom = []\n",
    "def Verification_RSS(req, site):  # vérifie s'il y a du rss dans un site\n",
    "    global liste_site_bon_rss\n",
    "    split = enlever(req.text)\n",
    "    for i in split:\n",
    "        if \"rss\" in i.lower() and str(site + \"\\n\") not in liste_site_bon_rss: # Vérifie s'il y a le rss ou RSS dans le html du site  # on vérifie que le site n'est pas deja dans la liste\n",
    "            liste_site_bon_rss.append(site + \"\\n\") # on met un \"\\n\" pour retourner à la ligne lors de l'ajout du dans le csv\n",
    "    New_CSV_site(\"Csv_Site/site_bon_rss.csv\", liste_site_bon_rss) # une foi les sites ajouter dans la liste, on crée un csv pour faciliter la lecture par la suite.\n",
    "\n",
    "def Verification_atom(req, site):  # vérifie s'il y a \"atom\" dans un site (même fonction qu'au-dessus mais pour atom)\n",
    "    global liste_site_bon_atom\n",
    "    split = req.text.split(\"\\n\")\n",
    "    for i in split:\n",
    "        if \"atom\" in i and str(site + \"\\n\") not in liste_site_bon_atom:\n",
    "            liste_site_bon_atom.append(site + \"\\n\")\n",
    "    New_CSV_site(\"Csv_Site/site_bon_atom.csv\", liste_site_bon_atom)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "\n",
    "def Connexion_site(dossier_csv):\n",
    "    with open(dossier_csv, \"r\") as f: # on ouvre un csv en parametre afin d'en examiner plusieurs\n",
    "        readCSV = csv.reader(f)\n",
    "        for i in readCSV:\n",
    "            print(\"lien en cours\", i) # c'est juste pour verifier que le programme de beug pas\n",
    "            try:\n",
    "                req = requests.get(\"\".join(i)) # \"\".join(i) permet de relier le lien du site, car sinon il est séparé et on ne peut pas le traiter # on récupère la requests du site auquel on se connecte\n",
    "                if req.status_code == requests.codes.ok: # si le site répond par une réponse 200\n",
    "                    Verification_RSS(req, \"\".join(i)) # lance les fonctions au-dessus avec en paramètre la requests au site et le lien du site pour l'ajouter dans une liste afin de l'ajouter dans un csv par la suite\n",
    "                    Verification_atom(req, \"\".join(i))\n",
    "                else:\n",
    "                    print(\"ca marche pas : \", i) # pour voir quel site ne fonctionne pas\n",
    "            except:\n",
    "                print(\"lien dead\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "def recuperation_des_sites():\n",
    "    Connexion_site(\"Csv_Site/sites.csv\") # on appelle 3 fois la fonction avec nos 3 fichiers csv avec nos sites\n",
    "    Connexion_site(\"Csv_Site/cybersecurity2.csv\")\n",
    "    Connexion_site(\"Csv_Site/message.csv\")\n",
    "    print(\"Terminé\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lien en cours ['https://www.cert.ssi.gouv.fr/']\n",
      "lien dead\n",
      "lien en cours ['https://www.ssi.gouv.fr/']\n",
      "lien dead\n",
      "lien en cours ['https://www.zataz.com/']\n",
      "lien dead\n",
      "lien en cours ['https://www.usine-digitale.fr/cybersecurite/']\n",
      "lien dead\n",
      "lien en cours ['https://www.silicon.fr/tag/cybersecurite']\n",
      "lien dead\n",
      "lien en cours ['https://www.itsecurityguru.org/']\n",
      "lien dead\n",
      "lien en cours ['https://securityweekly.com/']\n",
      "lien dead\n",
      "lien en cours ['https://www.infosecurity-magazine.com/']\n",
      "lien dead\n",
      "lien en cours ['https://www.futura-sciences.com/tech/cybersecurite/actualites/']\n",
      "lien dead\n",
      "lien en cours ['https://siecledigital.fr/cybersecurite/']\n",
      "lien dead\n",
      "lien en cours ['https://www.lemondeinformatique.fr/securite-informatique-3.html']\n",
      "lien dead\n",
      "lien en cours ['https://www.rtl.fr/sujet/cybersecurite']\n",
      "lien dead\n",
      "lien en cours ['https://www.zdnet.fr/actualites/cybersecurite-3900046206q.htm']\n",
      "lien dead\n",
      "lien en cours ['https://www.cyberocc.com/sinformer/actualites-cyber/']\n",
      "lien dead\n",
      "lien en cours ['https://cyware.com/cyber-security-news-articles']\n",
      "lien dead\n",
      "lien en cours ['https://thehackernews.com/']\n",
      "lien dead\n",
      "lien en cours ['https://www.securityweek.com/']\n",
      "lien dead\n",
      "lien en cours ['https://www.wired.com/tag/cybersecurity/']\n",
      "lien dead\n",
      "lien en cours ['https://cybernews.com/']\n",
      "ca marche pas :  ['https://cybernews.com/']\n",
      "lien en cours ['https://cybersecuritynews.com/']\n",
      "lien dead\n",
      "lien en cours ['https://www.cnbc.com/cybersecurity/']\n",
      "lien dead\n",
      "lien en cours ['https://threatpost.com/']\n",
      "lien dead\n",
      "lien en cours ['https://www.ncsc.gov.uk/']\n",
      "lien dead\n",
      "lien en cours ['https://muckrack.com/media-outlet/nationalcybersecuritynews']\n",
      "ca marche pas :  ['https://muckrack.com/media-outlet/nationalcybersecuritynews']\n",
      "lien en cours ['https://portswigger.net/daily-swig']\n",
      "lien dead\n",
      "lien en cours ['https://cybersecurity.att.com/blogs']\n",
      "lien dead\n",
      "lien en cours ['https://grahamcluley.com/']\n",
      "lien dead\n",
      "lien en cours ['https://www.schneier.com/blog/archives/2022/10/regulating-daos.html']\n",
      "lien dead\n",
      "lien en cours ['https://krebsonsecurity.com/']\n",
      "lien dead\n",
      "lien en cours ['https://www.csoonline.com/']\n",
      "lien dead\n",
      "lien en cours ['https://www.darkreading.com/']\n",
      "lien dead\n",
      "lien en cours ['https://www.welivesecurity.com/']\n",
      "lien dead\n",
      "lien en cours ['https://nakedsecurity.sophos.com/']\n",
      "lien dead\n",
      "lien en cours ['https://www.bleepingcomputer.com/']\n"
     ]
    }
   ],
   "source": [
    "recuperation_des_sites()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "def recuperation_lien_rss():  # recupere le lien du rss\n",
    "    csvv = open(\"Csv_Site/lien_rss.csv\", \"w\", newline='', encoding='utf-8')\n",
    "    with open(\"Csv_Site/site_bon_rss.csv\", \"r\") as f:\n",
    "        readCSV = csv.reader(f)\n",
    "        for i in readCSV:\n",
    "            print ('lien en cours : ' , i)\n",
    "            try:\n",
    "                st = requests.get(i[-1]).text.replace(\"'\", '\"')\n",
    "            except:\n",
    "                continue\n",
    "            balise_complet,lien = \"\",\"\"\n",
    "            bool_balise,balise_lien = False,False\n",
    "            # temp = []\n",
    "            for j in range(len(st)-1):  # on check char par char\n",
    "\n",
    "                #Check si c'est le debut d'une balise <a ... >\n",
    "                if st[j] + st[j + 1] == \"<a\":\n",
    "                    bool_balise = True\n",
    "\n",
    "                #check si c'est une balise fermante de <a ... > soit </a> on met bool_balise a false pour arreter de recuperer les idnex\n",
    "                if st[j - 4] + st[j - 3] + st[j - 2] + st[j - 1] == \"</a>\":  # check si fin\n",
    "                    bool_balise = False\n",
    "                    if \"rss\" in balise_complet.lower() and \"#\" not in balise_complet:\n",
    "\n",
    "                        #parfois c'est juste le /feed/ etc sans le lien devant\n",
    "                        if \"http\" not in lien:\n",
    "                            csvv.write(i[-1][:-1] + lien + \"\\n\")\n",
    "                        else:\n",
    "                            csvv.write(lien + \"\\n\")\n",
    "                        # temp += lien,\n",
    "                    balise_complet,lien = \"\",\"\"\n",
    "\n",
    "                ####### Dans la var lien #######\n",
    "                #permet de pouvoir recuperer les index utiles Si True\n",
    "                if st[j - 6] + st[j - 5] + st[j - 4] + st[j - 3] + st[j - 2] + st[j - 1] == 'href=\"':\n",
    "                    balise_lien = True\n",
    "                #Si false, ne permet de plus de recuprer les index\n",
    "                if st[j] == '\"' and st[-1] != \"=\":  # check si fin\n",
    "                    balise_lien = False\n",
    "\n",
    "                #Ecriture si balise == True\n",
    "                if bool_balise:\n",
    "                    #dans la balise complet\n",
    "                    balise_complet += st[j]\n",
    "                    if balise_lien:\n",
    "                        #le lien\n",
    "                        lien += st[j]\n",
    "    csvv.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recuperation_lien_rss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "def recuperation_atom():\n",
    "    liste_line_atom = []\n",
    "    with open(\"Csv_Site/site_bon_atom.csv\", \"r\") as f: # boucle dans le fichier csv ou il y a les sites possedant des lien atom\n",
    "        readCSV = csv.reader(f)\n",
    "        for i in readCSV: # on fait tourner i dans le csv (ici i va être égale à chaque lettre du fichier)\n",
    "            print ('lien en cours : ' , i)\n",
    "            req = requests.get(\"\".join(i)) # envoie une requête au site du fichier csv\n",
    "            split = req.text.split(\"\\n\") # on split la chaine à chaque fois qu'il y a un retour à la ligne pour sépararer chaque ligne de l'html\n",
    "            for j in split: # on fait tourner j dans le split (ici j va être égale a chaque ligne du fichier)\n",
    "                if \"atom\" in j: # si il y a atom dans la ligne html\n",
    "                    liste_line_atom.append(j + \"\\n\") # si on trouve atom, on ajoute la ligne avec un retour à la ligne a la fin dans la liste\n",
    "    with open(\"Csv_Site/line_atom.csv\", \"w\", newline='', encoding='utf-8') as f: # puis on ajoute tout dans un csv\n",
    "        for i in liste_line_atom:\n",
    "            f.write(i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lien en cours :  ['https://www.rtl.fr/sujet/cybersecurite']\n",
      "lien en cours :  ['https://thehackernews.com/']\n",
      "lien en cours :  ['https://www.schneier.com/blog/archives/2022/10/regulating-daos.html']\n",
      "lien en cours :  ['https://www.helpnetsecurity.com/']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [94], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mrecuperation_atom\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn [93], line 7\u001B[0m, in \u001B[0;36mrecuperation_atom\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m readCSV: \u001B[38;5;66;03m# on fait tourner i dans le csv (ici i va être égale à chaque lettre du fichier)\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28mprint\u001B[39m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlien en cours : \u001B[39m\u001B[38;5;124m'\u001B[39m , i)\n\u001B[0;32m----> 7\u001B[0m     req \u001B[38;5;241m=\u001B[39m \u001B[43mrequests\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# envoie une requête au site du fichier csv\u001B[39;00m\n\u001B[1;32m      8\u001B[0m     split \u001B[38;5;241m=\u001B[39m req\u001B[38;5;241m.\u001B[39mtext\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;66;03m# on split la chaine à chaque fois qu'il y a un retour à la ligne pour sépararer chaque ligne de l'html\u001B[39;00m\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m split: \u001B[38;5;66;03m# on fait tourner j dans le split (ici j va être égale a chaque ligne du fichier)\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/Recup_Flux_RSS/venv/lib/python3.9/site-packages/requests/api.py:73\u001B[0m, in \u001B[0;36mget\u001B[0;34m(url, params, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(url, params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     63\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a GET request.\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \n\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mget\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Recup_Flux_RSS/venv/lib/python3.9/site-packages/requests/api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[0;34m(method, url, **kwargs)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Recup_Flux_RSS/venv/lib/python3.9/site-packages/requests/sessions.py:587\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    582\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    583\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    584\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    585\u001B[0m }\n\u001B[1;32m    586\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 587\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    589\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m~/PycharmProjects/Recup_Flux_RSS/venv/lib/python3.9/site-packages/requests/sessions.py:701\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    698\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[1;32m    700\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[0;32m--> 701\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[1;32m    704\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[0;32m~/PycharmProjects/Recup_Flux_RSS/venv/lib/python3.9/site-packages/requests/adapters.py:489\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    487\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    488\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m chunked:\n\u001B[0;32m--> 489\u001B[0m         resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    491\u001B[0m \u001B[43m            \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    492\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m            \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m            \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    495\u001B[0m \u001B[43m            \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    496\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    497\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    498\u001B[0m \u001B[43m            \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    499\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    502\u001B[0m     \u001B[38;5;66;03m# Send the request.\u001B[39;00m\n\u001B[1;32m    503\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    504\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(conn, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mproxy_pool\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/PycharmProjects/Recup_Flux_RSS/venv/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_proxy(conn)\n\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Make the request on the httplib connection object.\u001B[39;00m\n\u001B[0;32m--> 703\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    704\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    706\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    711\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    713\u001B[0m \u001B[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001B[39;00m\n\u001B[1;32m    714\u001B[0m \u001B[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001B[39;00m\n\u001B[1;32m    715\u001B[0m \u001B[38;5;66;03m# it will also try to release it and we'll have a double-release\u001B[39;00m\n\u001B[1;32m    716\u001B[0m \u001B[38;5;66;03m# mess.\u001B[39;00m\n\u001B[1;32m    717\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/Recup_Flux_RSS/venv/lib/python3.9/site-packages/urllib3/connectionpool.py:449\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    444\u001B[0m             httplib_response \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39mgetresponse()\n\u001B[1;32m    445\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    446\u001B[0m             \u001B[38;5;66;03m# Remove the TypeError from the exception chain in\u001B[39;00m\n\u001B[1;32m    447\u001B[0m             \u001B[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001B[39;00m\n\u001B[1;32m    448\u001B[0m             \u001B[38;5;66;03m# Otherwise it looks like a bug in the code.\u001B[39;00m\n\u001B[0;32m--> 449\u001B[0m             \u001B[43msix\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    451\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_timeout(err\u001B[38;5;241m=\u001B[39me, url\u001B[38;5;241m=\u001B[39murl, timeout_value\u001B[38;5;241m=\u001B[39mread_timeout)\n",
      "File \u001B[0;32m<string>:3\u001B[0m, in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/Recup_Flux_RSS/venv/lib/python3.9/site-packages/urllib3/connectionpool.py:444\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    441\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    442\u001B[0m     \u001B[38;5;66;03m# Python 3\u001B[39;00m\n\u001B[1;32m    443\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 444\u001B[0m         httplib_response \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    445\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    446\u001B[0m         \u001B[38;5;66;03m# Remove the TypeError from the exception chain in\u001B[39;00m\n\u001B[1;32m    447\u001B[0m         \u001B[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001B[39;00m\n\u001B[1;32m    448\u001B[0m         \u001B[38;5;66;03m# Otherwise it looks like a bug in the code.\u001B[39;00m\n\u001B[1;32m    449\u001B[0m         six\u001B[38;5;241m.\u001B[39mraise_from(e, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:1347\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1345\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1346\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1347\u001B[0m         \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbegin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1348\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n\u001B[1;32m   1349\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:307\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;66;03m# read until we get a non-100 response\u001B[39;00m\n\u001B[1;32m    306\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 307\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    308\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n\u001B[1;32m    309\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py:268\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    267\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_read_status\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 268\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_MAXLINE\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso-8859-1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    269\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(line) \u001B[38;5;241m>\u001B[39m _MAXLINE:\n\u001B[1;32m    270\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m LineTooLong(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus line\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/socket.py:704\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    703\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 704\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    706\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py:1241\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1237\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1238\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1239\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1240\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1241\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1242\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1243\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py:1099\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1097\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1098\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1099\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1100\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "recuperation_atom()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "def recuperation_lien_atom():\n",
    "\n",
    "    ecriture = open (\"Csv_Site/lien_atom.csv\", \"w\", newline='', encoding='utf-8')\n",
    "    with open(\"Csv_Site/line_atom.csv\", \"r\") as f:\n",
    "        f = ''.join(f.readlines())\n",
    "        # print(list(map(str,f)))\n",
    "        balise_complet,balise_lien = \"\",\"\"\n",
    "        bool_complet,bool_lien = False,False\n",
    "        # temp = []\n",
    "        for i in range(len(f) - 1):\n",
    "            # si on croise <a on met g true afin de pouvoir ecrire\n",
    "            if f[i] + f[i + 1] == \"<a\":\n",
    "                bool_complet = True\n",
    "                # si on croise </a> on arrete l'ecriture avec g==false ou si on croise \"> er que g==True pour eviter les div <div blabla ... \">\n",
    "            if f[i - 4] + f[i - 3] + f[i - 2] + f[i - 1] == \"</a>\" or (\n",
    "                    f[i - 2] + f[i - 1] == '\">' and bool_complet == True):  # check si fin\n",
    "                bool_complet = False\n",
    "                if \"atom\" in balise_complet.lower() and \"#\" not in balise_complet:  # eviter les les #\n",
    "                    # print(l.index(\"atom\"))\n",
    "                    tempo = balise_complet.index(\"atom\")\n",
    "                    # si    [pas de lettre ou de chiffre]atom[pas de lettre ou de chiffre] ou [pas de lettre ou de chiffre]atoms[pas de lettre ou de chiffre]\n",
    "                    if (balise_complet[tempo - 1].isalnum() == False and balise_complet[tempo + 4].isalnum() == False) or (\n",
    "                            balise_complet[tempo - 1].isalnum() == False and balise_complet[tempo + 5].isalnum() == False and balise_complet[\n",
    "                        tempo + 4] == \"s\"):\n",
    "                        # print(l)\n",
    "                        # temp += balise_lien,\n",
    "                        ecriture.write(balise_lien+\"\\n\")\n",
    "                        print ('lien en cours : ' , balise_lien)\n",
    "                # print(l)\n",
    "                # on renitialise tout\n",
    "                balise_complet = \"\"\n",
    "                balise_lien = \"\"\n",
    "                # si on croise href on met h true afin de pouvoir ecrire\n",
    "            if f[i - 6] + f[i - 5] + f[i - 4] + f[i - 3] + f[i - 2] + f[i - 1] == 'href=\"':\n",
    "                bool_lien = True\n",
    "                # si on croise \" et != = on met h false afin d'arreter l'ecriture\n",
    "            if f[i] == '\"' and f[i + 1] != \"=\":  # check si fin\n",
    "                bool_lien = False\n",
    "            if bool_complet:  # g == True on ecrit\n",
    "                balise_complet += f[i]\n",
    "                if bool_lien:  # h == True on ecrit\n",
    "                    balise_lien += f[i]\n",
    "    ecriture.close()\n",
    "    # with open (\"Csv_Site/lien_atom.csv\", \"w\", newline='', encoding='utf-8') as f:\n",
    "    #     for i in temp:\n",
    "    #         f.write(i+\"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recuperation_lien_atom()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "#fonction qui retire les balises dans des balises <description>\n",
    "#par ex : <description>J'aime les aptes a <p> vanille</p>!!!</description>\n",
    "#la fonction enlevera la balaise <p> et </p>\n",
    "def refra(court):\n",
    "    resultat=\"\"\n",
    "    des_bool_sign = True\n",
    "    court = enlever(court)\n",
    "    for l in range(len(court) - 3):\n",
    "        if court[l] == \"<\":\n",
    "            des_bool_sign = False\n",
    "        if court[l] == \">\":\n",
    "            des_bool_sign = True\n",
    "        if des_bool_sign and (court[l].isalnum() or court[l] not in \"<>{}[]\"):\n",
    "            if court[l] + court[l + 1] + court[l + 2] + court[l + 3] == \"http\":\n",
    "                resultat += \" \"\n",
    "            resultat += court[l]\n",
    "    return resultat\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "month = {'01': 'janauary',\n",
    "            '02': 'february',\n",
    "            '03': 'march',\n",
    "            '04': 'april',\n",
    "            '05': 'may',\n",
    "            '06': 'june',\n",
    "            '07': 'july',\n",
    "            '08': 'august',\n",
    "            '09': 'september',\n",
    "            '10': 'october',\n",
    "            '11': 'november',\n",
    "            '12': 'december'}\n",
    "\n",
    "#date_debut = datetime.datetime(2000, 10, 1)\n",
    "\n",
    "def datee(v, date_debut):\n",
    "    date = \" \"+v.lower().replace(\"-\",\" \").replace(\"/\",\" \").replace(\",\",\"\")\n",
    "    # a = \" 2022-10-14T14:30:45Z\".lower().replace(\"-\",\" \").replace(\"/\",\" \")\n",
    "\n",
    "    b= \"\"\n",
    "    #remplace les lettres par des espaces\n",
    "    for i in range(len(date)-1):\n",
    "        if ((date[i-1].isdigit() or date[i-1].isalpha()==False) and date[i].isalpha() and (date[i+1].isdigit() or date[i+1].isalpha()==False)) == True:\n",
    "            b+=\" \"\n",
    "        else:\n",
    "            b+=date[i]\n",
    "    # print(b)\n",
    "    date=b\n",
    "    # print(date)\n",
    "\n",
    "    current = {\"annee\": \"\", \"mois\": \"\", \"jour\": \"\"}\n",
    "\n",
    "    f=[]\n",
    "    c= False\n",
    "    b = []\n",
    "\n",
    "    for i in range(len(date)-4):\n",
    "\n",
    "\n",
    "        #check si c'est le jour/mois soit possede 2 chiffres\n",
    "\n",
    "        if date[i-1].isalnum()==date[i+2].isalnum()==False and date[i].isdigit()==date[i+1].isdigit()==True and (date[i+2] not in \":\" and date[i-1] not in \":\"):\n",
    "            f+=date[i]+date[i+1],\n",
    "\n",
    "        if date[i-1].isalnum()==date[i+1].isalnum()==False and date[i].isdigit()==True and (date[i+1] not in \":\" and date[i-1] not in \":\"):\n",
    "            f+=date[i]+date[i+1],\n",
    "\n",
    "        #check si c'est l'année soit possede 4 chiffres\n",
    "        if date[i-1].isalnum()==False and date[i].isdigit() and date[i+1].isdigit() and date[i+2].isdigit() and date[i+3].isdigit() and date[i+4].isalnum()==False and date[i+4] not in \":/-\" and date[i-1] not in \":/-\":\n",
    "            f+=date[i]+date[i+1]+date[i+2]+date[i+3],\n",
    "\n",
    "        #si on a des mois en lettre on converti et on insert direct dans le dictionnaire\n",
    "        for j,k in month.items():\n",
    "            if date[i]+date[i+1]+date[i+2] in k:\n",
    "                # print(j)\n",
    "                current[\"mois\"] = j\n",
    "                c=True\n",
    "    # print(f)\n",
    "    # print(current)\n",
    "    if len(f) >0:\n",
    "\n",
    "        #si il y a eu le mois en lettre\n",
    "        if c:\n",
    "            current[\"jour\"]=f[0]\n",
    "            current[\"annee\"]=f[-1]\n",
    "\n",
    "\n",
    "        #si il n'y a pas eu de mois en lettre\n",
    "        else:\n",
    "            # print(f)\n",
    "        #Seulement si on respect le format aaaa/mm/jj\n",
    "            current[\"annee\"] = f[0]\n",
    "            # current[\"mois\"] = f[1]\n",
    "            current[\"mois\"] = f[1]\n",
    "            current[\"jour\"] = f[-1]\n",
    "        #on convertit en format date\n",
    "        # print(current,\"-----------------------------------------\")\n",
    "        # print(c)\n",
    "\n",
    "        # try:\n",
    "        date_voulu = datetime.datetime(int(current[\"annee\"]), int(current[\"mois\"]), int(current[\"jour\"]))\n",
    "        # except:\n",
    "        #     date_voulu = datetime.datetime(int(current[\"annee\"]), int(current[\"jour\"]), int(current[\"mois\"]))\n",
    "\n",
    "        # print(date_voulu)\n",
    "        #on check si c'est > a date voulu\n",
    "        if date_debut<date_voulu:\n",
    "            return True\n",
    "    else:\n",
    "        print(f)\n",
    "        return False\n",
    "\n",
    "# date_voulue = datetime.datetime(2000, int(\"01\"), int(\"01\"))\n",
    "# datee(\"2022-10-14T14:30:45Z\",date_voulue)\n",
    "# datee(\"Wed, 02 Nov 2022 14:11:30 +0000\",date_voulue)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "def traducteur(phrase):\n",
    "    import requests, uuid, json\n",
    "\n",
    "    # Add your key and endpoint\n",
    "\n",
    "    #api key william azure translator creer de ma propre poche\n",
    "    key = \"fb8ce793c54347e19cdd06eced15d4a6\"\n",
    "    endpoint = \"https://api.cognitive.microsofttranslator.com\"\n",
    "\n",
    "    # location, also known as region.\n",
    "    # required if you're using a multi-service or regional (not global) resource. It can be found in the Azure portal on the Keys and Endpoint page.\n",
    "    location = \"francecentral\"\n",
    "\n",
    "    path = '/translate'\n",
    "    constructed_url = endpoint + path\n",
    "\n",
    "    params = {\n",
    "        'api-version': '3.0',\n",
    "        'to': ['fr']\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        'Ocp-Apim-Subscription-Key': key,\n",
    "        # location required if you're using a multi-service or regional (not global) resource.\n",
    "        'Ocp-Apim-Subscription-Region': location,\n",
    "        'Content-type': 'application/json',\n",
    "        'X-ClientTraceId': str(uuid.uuid4())\n",
    "    }\n",
    "\n",
    "    # You can pass more than one object in body.\n",
    "    body = [{\n",
    "        'text': phrase\n",
    "    }]\n",
    "    request = requests.post(constructed_url, params=params, headers=headers, json=body)\n",
    "    response = request.json()\n",
    "    return response[0]['translations'][0]['text']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    " # code avec librairie feedparser\n",
    "\n",
    "\n",
    "def parser_site(emplacement, mot, ecriture, date_voulue): # permet de récuperer les informations comme le titre, la description, la date et le lien de l'article qui comporte le mot recherché.\n",
    "    writer = csv.writer(ecriture) # pour éviter de réécrire plusieur foi la même chose\n",
    "    writer.writerow(''.join(mot)) # on ecrit le mot dans la première ligne\n",
    "    writer.writerow([\"title\", \"description\", \"date\", \"link\"]) # on écrit l'entête\n",
    "    with open(emplacement, \"r\", encoding='utf-8') as f:\n",
    "        check_doublon=[]\n",
    "        reader = csv.reader(f)\n",
    "        for i in reader:\n",
    "            print(\"lien en cours :\", i)\n",
    "            lib_feedparser = feedparser.parse(\"\".join(i)) # permet de parser nos sites\n",
    "            # print(lib_feedparser)\n",
    "            for j in range(len(lib_feedparser.entries)):\n",
    "                try:\n",
    "                    # print(lib_feedparser.entries[j].description)\n",
    "                    if lib_feedparser.entries[j].updated is not None and lib_feedparser.entries[j].description is not None and lib_feedparser.entries[j].title is not None and lib_feedparser.entries[j].link is not None :\n",
    "                        if mot.lower() in (rapid:=traducteur(refra(str(lib_feedparser.entries[j].title.lower())))) or mot.lower() in (rapid2:=traducteur(refra(str(lib_feedparser.entries[j].description.lower())))): # on les mets en lower pour être sûr de la comparaison\n",
    "                            data = rapid, rapid2, str(refra(lib_feedparser.entries[j].updated)) , refra(lib_feedparser.entries[j].link)\n",
    "                            if datee(lib_feedparser.entries[j].updated, date_voulue) and data not in check_doublon:\n",
    "                                print(data)\n",
    "                                #data = traducteur(str(refra(d.entries[j].title)), target_lang=\"FR\")), traducteur(str(refra(d.entries[j].description)), target_lang=\"FR\")), str(d.entries[j].updated) , refra(d.entries[j].link) # on ajoute dans data le titre traduit, la derscription traduit, la date d'update, et le lien de l'article\n",
    "                                writer.writerow(data) # et ensuite on les ajoute dans le csv\n",
    "                                check_doublon.append(data)\n",
    "                except:\n",
    "                    if lib_feedparser.entries[j].updated is not None and lib_feedparser.entries[j].title is not None and lib_feedparser.entries[j].link is not None :\n",
    "                        if mot.lower() in (rapid3:=traducteur(refra(str(lib_feedparser.entries[j].title.lower())))): # on les mets en lower pour être sûr de la comparaison\n",
    "                            data = rapid3,\"pas de description\", str(refra(lib_feedparser.entries[j].updated)) , refra(lib_feedparser.entries[j].link)\n",
    "                            print(lib_feedparser.entries[j].updated)\n",
    "                            if datee(lib_feedparser.entries[j].updated, date_voulue) and data not in check_doublon:\n",
    "                                # print(data)\n",
    "                                #data = traducteur(str(refra(d.entries[j].title)), target_lang=\"FR\")), traducteur(str(refra(d.entries[j].description)), target_lang=\"FR\")), str(d.entries[j].updated) , refra(d.entries[j].link) # on ajoute dans data le titre traduit, la derscription traduit, la date d'update, et le lien de l'article\n",
    "                                writer.writerow(data) # et ensuite on les ajoute dans le csv\n",
    "                                check_doublon.append(data)\n",
    "            # break\n",
    "\n",
    "# parser_site(\"Csv_Site/lien_rss.csv\", \"veille\", ecriture_rss:=open(\"recherche_rss.csv\", \"w\", newline='', encoding='utf-8'), datetime.datetime(2000, 1, 1))\n",
    "# ecriture_rss.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piratage\n",
      "lien en cours : ['https://www.cert.ssi.gouv.fr/feed/']\n",
      "lien en cours : ['https://www.cert.ssi.gouv.fr/feed/scada/']\n",
      "lien en cours : ['https://www.cert.ssi.gouv.fr/alerte/feed/']\n",
      "lien en cours : ['https://www.cert.ssi.gouv.fr/cti/feed/']\n",
      "lien en cours : ['https://www.cert.ssi.gouv.fr/avis/feed/']\n",
      "lien en cours : ['https://www.cert.ssi.gouv.fr/ioc/feed/']\n",
      "lien en cours : ['https://www.cert.ssi.gouv.fr/dur/feed/']\n",
      "lien en cours : ['https://www.cert.ssi.gouv.fr/actualite/feed/']\n"
     ]
    }
   ],
   "source": [
    "ecriture_rss = open(\"recherche_rss.csv\", \"w\", newline='', encoding='utf-8') # on affilie a ecriture l'ouverture du fichier csv où on veut ecrire les resultats\n",
    "ecriture_atom = open(\"recherche_atom.csv\", \"w\", newline='', encoding='utf-8') # on affilie a ecriture l'ouverture du fichier csv où on veut ecrire les resultats\n",
    "\n",
    "boolean = True\n",
    "\n",
    "while boolean:\n",
    "    mot = str(input(\"Entrez le mot/thèmes que vous souhaitez\")).lower() # pour faire une boucle tant qu'on sort pas pour afficher plusieurs mots\n",
    "    print(mot)\n",
    "\n",
    "    if mot == \"q\":\n",
    "        break\n",
    "    else:\n",
    "        annee_voulue = int(input(\"Entrez l'année jusqu'à quand les articles doivent au maximum datée \"))\n",
    "        mois_voulue = int(input(\"Entrez le mois jusqu'à quand les articles doivent au maximum datée \"))\n",
    "        jours_voulue = int(input(\"Entrez le jour jusqu'à quand les articles doivent au maximum datée \"))\n",
    "        date_voulue = datetime.datetime(annee_voulue, mois_voulue, jours_voulue)\n",
    "        parser_site(\"Csv_Site/lien_rss.csv\", mot, ecriture_rss, date_voulue) # on l'appelle 2 fois pour différencier le rss de l'atom\n",
    "        parser_site(\"Csv_Site/lien_atom.csv\", mot, ecriture_atom, date_voulue)\n",
    "\n",
    "\n",
    "ecriture_rss.close()\n",
    "ecriture_atom.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
